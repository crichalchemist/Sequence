{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Training Pipeline - Production Workflow\n",
    "\n",
    "This notebook provides a complete, production-ready training workflow for the Sequence framework.\n",
    "\n",
    "**Features:**\n",
    "- Requirements installation\n",
    "- Multi-pair sequential training\n",
    "- Real data loading from prepared CSV files\n",
    "- Train/validation/test splitting\n",
    "- Multi-GPU training support\n",
    "- Automatic Mixed Precision (AMP)\n",
    "- Early stopping and learning rate scheduling\n",
    "- Supervised learning (classification)\n",
    "- Reinforcement learning (SAC)\n",
    "- Checkpoint management\n",
    "- Comprehensive evaluation and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Requirements Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All requirements installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q numpy pandas matplotlib seaborn scikit-learn tqdm\n",
    "!pip install -q transformers backtesting ta\n",
    "\n",
    "print(\"âœ“ All requirements installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mode: SUPERVISED\n",
      "Pairs to train: ['eurusd', 'eurgbp', 'eurjpy', 'eurchf', 'euraud', 'eurcad', 'eurnzd', 'gbpusd', 'gbpjpy', 'gbpchf', 'gbpcad', 'gbpaud', 'gbpnzd', 'usdjpy', 'usdchf', 'usdcad', 'audusd', 'audjpy', 'audcad', 'audchf', 'audnzd', 'nzdusd', 'nzdjpy', 'nzdcad', 'nzdchf', 'cadchf', 'cadjpy', 'chfjpy', 'usdbrl', 'usdrub', 'usdinr', 'usdcny', 'usdzar', 'usdtry']\n",
      "Total pairs: 34\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MULTI-PAIR CONFIGURATION\n",
    "# =============================================================================\n",
    "# Training will run sequentially for each pair in the list\n",
    "PAIRS = [\n",
    "    \"eurusd\",\"eurgbp\",\"eurjpy\",\"eurchf\",\n",
    "    \"euraud\",\"eurcad\",\"eurnzd\",\"gbpusd\", \n",
    "    \"gbpjpy\",\"gbpchf\",\"gbpcad\",\"gbpaud\",\n",
    "    \"gbpnzd\",\"usdjpy\",\"usdchf\",\"usdcad\",\n",
    "    \"audusd\",\"audjpy\",\"audcad\",\"audchf\",\n",
    "    \"audnzd\",\"nzdusd\",\"nzdjpy\",\"nzdcad\",\n",
    "    \"nzdchf\",\"cadchf\",\"cadjpy\",\"chfjpy\",\n",
    "    \"usdbrl\",\"usdrub\",\"usdinr\",\"usdcny\",\n",
    "    \"usdzar\",\"usdtry\"\n",
    "]  # Add more pairs as needed\n",
    "\n",
    "# Training mode: 'supervised' or 'sac'\n",
    "TRAINING_MODE = \"supervised\"  # Options: 'supervised', 'sac'\n",
    "\n",
    "# Data configuration\n",
    "T_IN = 120  # Input sequence length\n",
    "T_OUT = 10  # Prediction horizon\n",
    "\n",
    "# =============================================================================\n",
    "# SUPERVISED LEARNING CONFIGURATION\n",
    "# =============================================================================\n",
    "SUPERVISED_CONFIG = {\n",
    "    # Model architecture\n",
    "    \"hidden_size_lstm\": 128,\n",
    "    \"num_layers_lstm\": 2,\n",
    "    \"cnn_num_filters\": 64,\n",
    "    \"attention_dim\": 128,\n",
    "    \"dropout\": 0.2,\n",
    "    \"num_classes\": 3,  # 3 for classification (down/neutral/up)\n",
    "    # Training hyperparameters\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"use_amp\": False,\n",
    "    # Data splitting\n",
    "    \"train_ratio\": 0.7,\n",
    "    \"val_ratio\": 0.15,\n",
    "    \"test_ratio\": 0.15,\n",
    "    # Checkpointing\n",
    "    \"checkpoint_dir\": \"models/checkpoints\",\n",
    "    \"early_stop_patience\": 5,\n",
    "    \"lr_scheduler_patience\": 3,\n",
    "    \"lr_scheduler_factor\": 0.5,\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# SAC (REINFORCEMENT LEARNING) CONFIGURATION\n",
    "# =============================================================================\n",
    "SAC_CONFIG = {\n",
    "    # Agent hyperparameters\n",
    "    \"hidden_dim\": 256,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"gamma\": 0.99,  # Discount factor\n",
    "    \"tau\": 0.005,  # Soft update coefficient\n",
    "    \"alpha\": 0.2,  # Entropy temperature (if not auto-tuning)\n",
    "    \"auto_entropy_tuning\": True,\n",
    "    # Training configuration\n",
    "    \"total_steps\": 100000,\n",
    "    \"batch_size\": 256,\n",
    "    \"replay_buffer_size\": 100000,\n",
    "    \"warmup_steps\": 1000,  # Random exploration steps\n",
    "    \"update_interval\": 1,  # Update every N steps\n",
    "    \"eval_interval\": 5000,  # Evaluate every N steps\n",
    "    \"eval_episodes\": 10,\n",
    "    # Environment configuration\n",
    "    \"initial_cash\": 50000.0,\n",
    "    \"time_horizon\": 100,\n",
    "    \"commission_pct\": 0.0001,  # 0.01%\n",
    "    \"spread_bps\": 1.0,  # 1 basis point\n",
    "    \"reward_type\": \"incremental_pnl\",  # Options: 'portfolio_value', 'incremental_pnl', 'sharpe', 'cost_aware'\n",
    "    \"reward_scaling\": 1.0,\n",
    "    # Checkpointing\n",
    "    \"checkpoint_dir\": \"models/sac_checkpoints\",\n",
    "    \"save_interval\": 10000,\n",
    "}\n",
    "\n",
    "print(f\"Training mode: {TRAINING_MODE.upper()}\")\n",
    "print(f\"Pairs to train: {PAIRS}\")\n",
    "print(f\"Total pairs: {len(PAIRS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /content\n",
      "\n",
      "Parent directory: /\n",
      "\n",
      "Contents of current dir:\n",
      "  ðŸ“ .config\n",
      "  ðŸ“ sample_data\n",
      "\n",
      "Contents of parent dir:\n",
      "  ðŸ“„ .dockerenv\n",
      "  ðŸ“„ NGC-DL-CONTAINER-LICENSE\n",
      "  ðŸ“ bin\n",
      "  ðŸ“ boot\n",
      "  ðŸ“ content\n",
      "  ðŸ“„ cuda-keyring_1.1-1_all.deb\n",
      "  ðŸ“ datalab\n",
      "  ðŸ“ dev\n",
      "  ðŸ“ etc\n",
      "  ðŸ“ home\n",
      "  ðŸ“ kaggle\n",
      "  ðŸ“ lib\n",
      "  ðŸ“ lib32\n",
      "  ðŸ“ lib64\n",
      "  ðŸ“ libx32\n",
      "  ðŸ“ media\n",
      "  ðŸ“ mnt\n",
      "  ðŸ“ opt\n",
      "  ðŸ“ proc\n",
      "  ðŸ“ python-apt\n"
     ]
    }
   ],
   "source": [
    "  from pathlib import Path\n",
    "  import os\n",
    "\n",
    "  print(\"Current directory:\", Path.cwd())\n",
    "  print(\"\\nParent directory:\", Path.cwd().parent)\n",
    "  print(\"\\nContents of current dir:\")\n",
    "  for item in sorted(Path.cwd().iterdir())[:20]:\n",
    "      prefix = \"ðŸ“\" if item.is_dir() else \"ðŸ“„\"\n",
    "      print(f\"  {prefix} {item.name}\")\n",
    "\n",
    "  print(\"\\nContents of parent dir:\")\n",
    "  for item in sorted(Path.cwd().parent.iterdir())[:20]:\n",
    "      prefix = \"ðŸ“\" if item.is_dir() else \"ðŸ“„\"\n",
    "      print(f\"  {prefix} {item.name}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unwrapped_model(model):\n",
    "    \"\"\"Get the underlying model from DataParallel wrapper.\"\"\"\n",
    "    return model.module if isinstance(model, nn.DataParallel) else model\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"Format seconds into human-readable time.\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    \n",
    "    if hours > 0:\n",
    "        return f\"{hours}h {minutes}m {secs}s\"\n",
    "    elif minutes > 0:\n",
    "        return f\"{minutes}m {secs}s\"\n",
    "    else:\n",
    "        return f\"{secs}s\"\n",
    "\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for time series sequences.\"\"\"\n",
    "    \n",
    "    def __init__(self, features, targets, t_in):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.LongTensor(targets) if targets.dtype == np.int64 else torch.FloatTensor(targets)\n",
    "        self.t_in = t_in\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.t_in\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx:idx + self.t_in]\n",
    "        y = self.targets[idx + self.t_in]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Supervised Learning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_supervised(model, loader, criterion, optimizer, device, scaler=None, grad_clip=None):\n",
    "    \"\"\"Train for one epoch (supervised learning).\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for x, y in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scaler:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            if grad_clip:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            if grad_clip:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += predicted.eq(y).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "\n",
    "def validate_supervised(model, loader, criterion, device):\n",
    "    \"\"\"Validate the model (supervised learning).\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "\n",
    "def train_supervised(pair, config):\n",
    "    \"\"\"Complete supervised training pipeline for a single pair.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SUPERVISED TRAINING: {pair.upper()}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load data\n",
    "    data_path = ROOT / 'data' / 'data' / pair / f'{pair}_prepared.csv'\n",
    "    print(f\"Loading data from: {data_path}\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"âœ“ Loaded {len(df):,} rows\\n\")\n",
    "    \n",
    "    # Separate features and targets\n",
    "    target_col = 'target' if 'target' in df.columns else 'label'\n",
    "    feature_cols = [col for col in df.columns if col not in [target_col, 'timestamp', 'date', 'time']]\n",
    "    features = df[feature_cols].values\n",
    "    targets = df[target_col].values\n",
    "    \n",
    "    # Split data\n",
    "    n_samples = len(features)\n",
    "    train_end = int(n_samples * config['train_ratio'])\n",
    "    val_end = int(n_samples * (config['train_ratio'] + config['val_ratio']))\n",
    "    \n",
    "    train_features, train_targets = features[:train_end], targets[:train_end]\n",
    "    val_features, val_targets = features[train_end:val_end], targets[train_end:val_end]\n",
    "    test_features, test_targets = features[val_end:], targets[val_end:]\n",
    "    \n",
    "    print(f\"Dataset split:\")\n",
    "    print(f\"  Train: {len(train_features):,} samples ({config['train_ratio']*100:.0f}%)\")\n",
    "    print(f\"  Val:   {len(val_features):,} samples ({config['val_ratio']*100:.0f}%)\")\n",
    "    print(f\"  Test:  {len(test_features):,} samples ({config['test_ratio']*100:.0f}%)\\n\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = SequenceDataset(train_features, train_targets, T_IN)\n",
    "    val_dataset = SequenceDataset(val_features, val_targets, T_IN)\n",
    "    test_dataset = SequenceDataset(test_features, test_targets, T_IN)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    # Create model\n",
    "    model_config = ModelConfig(\n",
    "        num_features=len(feature_cols),\n",
    "        hidden_size_lstm=config['hidden_size_lstm'],\n",
    "        num_layers_lstm=config['num_layers_lstm'],\n",
    "        cnn_num_filters=config['cnn_num_filters'],\n",
    "        attention_dim=config['attention_dim'],\n",
    "        dropout=config['dropout'],\n",
    "        num_classes=config['num_classes'],\n",
    "        use_optimized_attention=False\n",
    "    )\n",
    "    \n",
    "    model = HybridCNNLSTMAttention(model_config)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model, device = setup_multi_gpu(model, device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Model: HybridCNNLSTMAttention ({total_params:,} parameters)\")\n",
    "    print(f\"Device: {device}\\n\")\n",
    "    \n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=config['lr_scheduler_factor'], \n",
    "        patience=config['lr_scheduler_patience'], verbose=False\n",
    "    )\n",
    "    scaler = torch.cuda.amp.GradScaler() if config['use_amp'] and torch.cuda.is_available() else None\n",
    "    \n",
    "    # Checkpoint directory\n",
    "    checkpoint_dir = ROOT / config['checkpoint_dir']\n",
    "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "    checkpoint_path = checkpoint_dir / f'{pair}_best_model.pt'\n",
    "    \n",
    "    # Training loop\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(f\"Starting training for {config['epochs']} epochs...\\n\")\n",
    "    \n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_acc = train_epoch_supervised(\n",
    "            model, train_loader, criterion, optimizer, device, scaler, config['grad_clip']\n",
    "        )\n",
    "        val_loss, val_acc = validate_supervised(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f\"Epoch {epoch:3d}/{config['epochs']} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}% | \"\n",
    "                  f\"LR: {current_lr:.2e}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': get_unwrapped_model(model).state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc,\n",
    "                'model_config': model_config.__dict__,\n",
    "                'pair': pair,\n",
    "                'history': history\n",
    "            }, checkpoint_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= config['early_stop_patience']:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    # Test evaluation\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    get_unwrapped_model(model).load_state_dict(checkpoint['model_state_dict'])\n",
    "    test_loss, test_acc = validate_supervised(model, test_loader, criterion, device)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING COMPLETE: {pair.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Time elapsed: {format_time(elapsed_time)}\")\n",
    "    print(f\"Best val loss: {best_val_loss:.4f} (epoch {checkpoint['epoch']})\")\n",
    "    print(f\"Test loss: {test_loss:.4f}\")\n",
    "    print(f\"Test accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"Checkpoint: {checkpoint_path}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'pair': pair,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'test_loss': test_loss,\n",
    "        'test_acc': test_acc,\n",
    "        'epochs_trained': len(history['train_loss']),\n",
    "        'time_elapsed': elapsed_time,\n",
    "        'checkpoint_path': str(checkpoint_path)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SAC (Reinforcement Learning) Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sac_agent(agent, env, num_episodes=10):\n",
    "    \"\"\"Evaluate SAC agent over multiple episodes.\"\"\"\n",
    "    episode_rewards = []\n",
    "    episode_lengths = []\n",
    "    \n",
    "    for _ in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "        episode_length = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            # Get state vector from observation\n",
    "            state = np.array([obs['portfolio_value'], obs['position'], obs['cash']])\n",
    "            action = agent.select_action(state, evaluate=True)\n",
    "            \n",
    "            # Convert continuous action to OrderAction\n",
    "            size = abs(action[0]) * 10.0  # Scale action\n",
    "            side = 'buy' if action[0] > 0 else 'sell'\n",
    "            order = OrderAction(action_type='market', side=side, size=size)\n",
    "            \n",
    "            obs, reward, done, info = env.step(order)\n",
    "            episode_reward += reward\n",
    "            episode_length += 1\n",
    "        \n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_lengths.append(episode_length)\n",
    "    \n",
    "    return {\n",
    "        'mean_reward': np.mean(episode_rewards),\n",
    "        'std_reward': np.std(episode_rewards),\n",
    "        'mean_length': np.mean(episode_lengths)\n",
    "    }\n",
    "\n",
    "\n",
    "def train_sac(pair, config):\n",
    "    \"\"\"Complete SAC training pipeline for a single pair.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SAC TRAINING: {pair.upper()}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load data for environment\n",
    "    data_path = ROOT / 'data' / 'data' / pair / f'{pair}_prepared.csv'\n",
    "    print(f\"Loading data from: {data_path}\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"âœ“ Loaded {len(df):,} rows\\n\")\n",
    "    \n",
    "    # Create execution environment\n",
    "    exec_config = ExecutionConfig(\n",
    "        initial_cash=config['initial_cash'],\n",
    "        time_horizon=config['time_horizon'],\n",
    "        commission_pct=config['commission_pct'],\n",
    "        spread_bps=config['spread_bps'],\n",
    "        reward_type=config['reward_type'],\n",
    "        reward_scaling=config['reward_scaling']\n",
    "    )\n",
    "    \n",
    "    env = SimulatedRetailExecutionEnv(exec_config, seed=42)\n",
    "    print(f\"Environment: SimulatedRetailExecutionEnv\")\n",
    "    print(f\"  Initial cash: ${config['initial_cash']:,.2f}\")\n",
    "    print(f\"  Time horizon: {config['time_horizon']} steps\")\n",
    "    print(f\"  Reward type: {config['reward_type']}\\n\")\n",
    "    \n",
    "    # Create SAC agent\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    state_dim = 3  # portfolio_value, position, cash\n",
    "    action_dim = 1  # continuous action (trade size)\n",
    "    \n",
    "    agent = SACAgent(\n",
    "        state_dim=state_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_dim=config['hidden_dim'],\n",
    "        lr=config['learning_rate'],\n",
    "        gamma=config['gamma'],\n",
    "        tau=config['tau'],\n",
    "        alpha=config['alpha'],\n",
    "        auto_entropy_tuning=config['auto_entropy_tuning'],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(f\"SAC Agent created (device: {device})\")\n",
    "    print(f\"  State dim: {state_dim}\")\n",
    "    print(f\"  Action dim: {action_dim}\")\n",
    "    print(f\"  Hidden dim: {config['hidden_dim']}\")\n",
    "    print(f\"  Auto entropy tuning: {config['auto_entropy_tuning']}\\n\")\n",
    "    \n",
    "    # Replay buffer\n",
    "    replay_buffer = ReplayBuffer(capacity=config['replay_buffer_size'])\n",
    "    \n",
    "    # Checkpoint directory\n",
    "    checkpoint_dir = ROOT / config['checkpoint_dir']\n",
    "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Training loop\n",
    "    print(f\"Starting SAC training for {config['total_steps']:,} steps...\\n\")\n",
    "    \n",
    "    obs = env.reset()\n",
    "    episode_reward = 0\n",
    "    episode_length = 0\n",
    "    episode_num = 0\n",
    "    \n",
    "    episode_rewards = []\n",
    "    update_metrics = []\n",
    "    \n",
    "    for step in tqdm(range(1, config['total_steps'] + 1), desc=\"Training\"):\n",
    "        # Get state\n",
    "        state = np.array([obs['portfolio_value'], obs['position'], obs['cash']])\n",
    "        \n",
    "        # Select action\n",
    "        if step < config['warmup_steps']:\n",
    "            action = np.random.uniform(-1, 1, size=(action_dim,))\n",
    "        else:\n",
    "            action = agent.select_action(state, evaluate=False)\n",
    "        \n",
    "        # Convert to OrderAction\n",
    "        size = abs(action[0]) * 10.0\n",
    "        side = 'buy' if action[0] > 0 else 'sell'\n",
    "        order = OrderAction(action_type='market', side=side, size=size)\n",
    "        \n",
    "        # Step environment\n",
    "        next_obs, reward, done, info = env.step(order)\n",
    "        next_state = np.array([next_obs['portfolio_value'], next_obs['position'], next_obs['cash']])\n",
    "        \n",
    "        # Store transition\n",
    "        replay_buffer.add(state, action[0], reward, next_state, done)\n",
    "        \n",
    "        episode_reward += reward\n",
    "        episode_length += 1\n",
    "        obs = next_obs\n",
    "        \n",
    "        # Update agent\n",
    "        if len(replay_buffer) >= config['batch_size'] and step % config['update_interval'] == 0:\n",
    "            metrics = agent.update(replay_buffer, batch_size=config['batch_size'])\n",
    "            update_metrics.append(metrics)\n",
    "        \n",
    "        # Episode end\n",
    "        if done:\n",
    "            episode_rewards.append(episode_reward)\n",
    "            episode_num += 1\n",
    "            obs = env.reset()\n",
    "            episode_reward = 0\n",
    "            episode_length = 0\n",
    "        \n",
    "        # Evaluation\n",
    "        if step % config['eval_interval'] == 0:\n",
    "            eval_results = evaluate_sac_agent(agent, env, num_episodes=config['eval_episodes'])\n",
    "            print(f\"\\nStep {step:6d} | \"\n",
    "                  f\"Episodes: {episode_num} | \"\n",
    "                  f\"Eval reward: {eval_results['mean_reward']:.2f} Â± {eval_results['std_reward']:.2f} | \"\n",
    "                  f\"Alpha: {agent.alpha:.3f}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if step % config['save_interval'] == 0:\n",
    "            checkpoint_path = checkpoint_dir / f'{pair}_sac_step_{step}.pt'\n",
    "            agent.save(str(checkpoint_path))\n",
    "    \n",
    "    # Final evaluation\n",
    "    final_eval = evaluate_sac_agent(agent, env, num_episodes=50)\n",
    "    \n",
    "    # Save final checkpoint\n",
    "    final_checkpoint = checkpoint_dir / f'{pair}_sac_final.pt'\n",
    "    agent.save(str(final_checkpoint))\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SAC TRAINING COMPLETE: {pair.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Time elapsed: {format_time(elapsed_time)}\")\n",
    "    print(f\"Total episodes: {episode_num}\")\n",
    "    print(f\"Final eval reward: {final_eval['mean_reward']:.2f} Â± {final_eval['std_reward']:.2f}\")\n",
    "    print(f\"Checkpoint: {final_checkpoint}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'pair': pair,\n",
    "        'total_episodes': episode_num,\n",
    "        'final_eval_reward_mean': final_eval['mean_reward'],\n",
    "        'final_eval_reward_std': final_eval['std_reward'],\n",
    "        'time_elapsed': elapsed_time,\n",
    "        'checkpoint_path': str(final_checkpoint)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Pair Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "MULTI-PAIR TRAINING SESSION\n",
      "################################################################################\n",
      "Mode: SUPERVISED\n",
      "Pairs: EURUSD, EURGBP, EURJPY, EURCHF, EURAUD, EURCAD, EURNZD, GBPUSD, GBPJPY, GBPCHF, GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "Total pairs: 34\n",
      "################################################################################\n",
      "\n",
      "\n",
      "[1/34] Processing EURUSD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: EURUSD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/eurusd/eurusd_prepared.csv\n",
      "âœ— EURUSD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurusd/eurusd_prepared.csv'\n",
      "\n",
      "Remaining pairs: EURGBP, EURJPY, EURCHF, EURAUD, EURCAD, EURNZD, GBPUSD, GBPJPY, GBPCHF, GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[2/34] Processing EURGBP...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: EURGBP\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/eurgbp/eurgbp_prepared.csv\n",
      "âœ— EURGBP failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurgbp/eurgbp_prepared.csv'\n",
      "\n",
      "Remaining pairs: EURJPY, EURCHF, EURAUD, EURCAD, EURNZD, GBPUSD, GBPJPY, GBPCHF, GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[3/34] Processing EURJPY...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: EURJPY\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/eurjpy/eurjpy_prepared.csv\n",
      "âœ— EURJPY failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurjpy/eurjpy_prepared.csv'\n",
      "\n",
      "Remaining pairs: EURCHF, EURAUD, EURCAD, EURNZD, GBPUSD, GBPJPY, GBPCHF, GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[4/34] Processing EURCHF...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: EURCHF\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/eurchf/eurchf_prepared.csv\n",
      "âœ— EURCHF failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurchf/eurchf_prepared.csv'\n",
      "\n",
      "Remaining pairs: EURAUD, EURCAD, EURNZD, GBPUSD, GBPJPY, GBPCHF, GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[5/34] Processing EURAUD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: EURAUD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/euraud/euraud_prepared.csv\n",
      "âœ— EURAUD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/euraud/euraud_prepared.csv'\n",
      "\n",
      "Remaining pairs: EURCAD, EURNZD, GBPUSD, GBPJPY, GBPCHF, GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[6/34] Processing EURCAD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: EURCAD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/eurcad/eurcad_prepared.csv\n",
      "âœ— EURCAD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurcad/eurcad_prepared.csv'\n",
      "\n",
      "Remaining pairs: EURNZD, GBPUSD, GBPJPY, GBPCHF, GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[7/34] Processing EURNZD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: EURNZD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/eurnzd/eurnzd_prepared.csv\n",
      "âœ— EURNZD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurnzd/eurnzd_prepared.csv'\n",
      "\n",
      "Remaining pairs: GBPUSD, GBPJPY, GBPCHF, GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[8/34] Processing GBPUSD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: GBPUSD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/gbpusd/gbpusd_prepared.csv\n",
      "âœ— GBPUSD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpusd/gbpusd_prepared.csv'\n",
      "\n",
      "Remaining pairs: GBPJPY, GBPCHF, GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[9/34] Processing GBPJPY...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: GBPJPY\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/gbpjpy/gbpjpy_prepared.csv\n",
      "âœ— GBPJPY failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpjpy/gbpjpy_prepared.csv'\n",
      "\n",
      "Remaining pairs: GBPCHF, GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[10/34] Processing GBPCHF...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: GBPCHF\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/gbpchf/gbpchf_prepared.csv\n",
      "âœ— GBPCHF failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpchf/gbpchf_prepared.csv'\n",
      "\n",
      "Remaining pairs: GBPCAD, GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[11/34] Processing GBPCAD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: GBPCAD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/gbpcad/gbpcad_prepared.csv\n",
      "âœ— GBPCAD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpcad/gbpcad_prepared.csv'\n",
      "\n",
      "Remaining pairs: GBPAUD, GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[12/34] Processing GBPAUD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: GBPAUD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/gbpaud/gbpaud_prepared.csv\n",
      "âœ— GBPAUD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpaud/gbpaud_prepared.csv'\n",
      "\n",
      "Remaining pairs: GBPNZD, USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[13/34] Processing GBPNZD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: GBPNZD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/gbpnzd/gbpnzd_prepared.csv\n",
      "âœ— GBPNZD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpnzd/gbpnzd_prepared.csv'\n",
      "\n",
      "Remaining pairs: USDJPY, USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[14/34] Processing USDJPY...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: USDJPY\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/usdjpy/usdjpy_prepared.csv\n",
      "âœ— USDJPY failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdjpy/usdjpy_prepared.csv'\n",
      "\n",
      "Remaining pairs: USDCHF, USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[15/34] Processing USDCHF...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: USDCHF\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/usdchf/usdchf_prepared.csv\n",
      "âœ— USDCHF failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdchf/usdchf_prepared.csv'\n",
      "\n",
      "Remaining pairs: USDCAD, AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[16/34] Processing USDCAD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: USDCAD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/usdcad/usdcad_prepared.csv\n",
      "âœ— USDCAD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdcad/usdcad_prepared.csv'\n",
      "\n",
      "Remaining pairs: AUDUSD, AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[17/34] Processing AUDUSD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: AUDUSD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/audusd/audusd_prepared.csv\n",
      "âœ— AUDUSD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/audusd/audusd_prepared.csv'\n",
      "\n",
      "Remaining pairs: AUDJPY, AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[18/34] Processing AUDJPY...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: AUDJPY\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/audjpy/audjpy_prepared.csv\n",
      "âœ— AUDJPY failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/audjpy/audjpy_prepared.csv'\n",
      "\n",
      "Remaining pairs: AUDCAD, AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[19/34] Processing AUDCAD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: AUDCAD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/audcad/audcad_prepared.csv\n",
      "âœ— AUDCAD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/audcad/audcad_prepared.csv'\n",
      "\n",
      "Remaining pairs: AUDCHF, AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[20/34] Processing AUDCHF...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: AUDCHF\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/audchf/audchf_prepared.csv\n",
      "âœ— AUDCHF failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/audchf/audchf_prepared.csv'\n",
      "\n",
      "Remaining pairs: AUDNZD, NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[21/34] Processing AUDNZD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: AUDNZD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/audnzd/audnzd_prepared.csv\n",
      "âœ— AUDNZD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/audnzd/audnzd_prepared.csv'\n",
      "\n",
      "Remaining pairs: NZDUSD, NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[22/34] Processing NZDUSD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: NZDUSD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/nzdusd/nzdusd_prepared.csv\n",
      "âœ— NZDUSD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/nzdusd/nzdusd_prepared.csv'\n",
      "\n",
      "Remaining pairs: NZDJPY, NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[23/34] Processing NZDJPY...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: NZDJPY\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/nzdjpy/nzdjpy_prepared.csv\n",
      "âœ— NZDJPY failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/nzdjpy/nzdjpy_prepared.csv'\n",
      "\n",
      "Remaining pairs: NZDCAD, NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[24/34] Processing NZDCAD...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: NZDCAD\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/nzdcad/nzdcad_prepared.csv\n",
      "âœ— NZDCAD failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/nzdcad/nzdcad_prepared.csv'\n",
      "\n",
      "Remaining pairs: NZDCHF, CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[25/34] Processing NZDCHF...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: NZDCHF\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/nzdchf/nzdchf_prepared.csv\n",
      "âœ— NZDCHF failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/nzdchf/nzdchf_prepared.csv'\n",
      "\n",
      "Remaining pairs: CADCHF, CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[26/34] Processing CADCHF...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: CADCHF\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/cadchf/cadchf_prepared.csv\n",
      "âœ— CADCHF failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/cadchf/cadchf_prepared.csv'\n",
      "\n",
      "Remaining pairs: CADJPY, CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[27/34] Processing CADJPY...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: CADJPY\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/cadjpy/cadjpy_prepared.csv\n",
      "âœ— CADJPY failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/cadjpy/cadjpy_prepared.csv'\n",
      "\n",
      "Remaining pairs: CHFJPY, USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[28/34] Processing CHFJPY...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: CHFJPY\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/chfjpy/chfjpy_prepared.csv\n",
      "âœ— CHFJPY failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/chfjpy/chfjpy_prepared.csv'\n",
      "\n",
      "Remaining pairs: USDBRL, USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[29/34] Processing USDBRL...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: USDBRL\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/usdbrl/usdbrl_prepared.csv\n",
      "âœ— USDBRL failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdbrl/usdbrl_prepared.csv'\n",
      "\n",
      "Remaining pairs: USDRUB, USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[30/34] Processing USDRUB...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: USDRUB\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/usdrub/usdrub_prepared.csv\n",
      "âœ— USDRUB failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdrub/usdrub_prepared.csv'\n",
      "\n",
      "Remaining pairs: USDINR, USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[31/34] Processing USDINR...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: USDINR\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/usdinr/usdinr_prepared.csv\n",
      "âœ— USDINR failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdinr/usdinr_prepared.csv'\n",
      "\n",
      "Remaining pairs: USDCNY, USDZAR, USDTRY\n",
      "\n",
      "[32/34] Processing USDCNY...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: USDCNY\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/usdcny/usdcny_prepared.csv\n",
      "âœ— USDCNY failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdcny/usdcny_prepared.csv'\n",
      "\n",
      "Remaining pairs: USDZAR, USDTRY\n",
      "\n",
      "[33/34] Processing USDZAR...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: USDZAR\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/usdzar/usdzar_prepared.csv\n",
      "âœ— USDZAR failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdzar/usdzar_prepared.csv'\n",
      "\n",
      "Remaining pairs: USDTRY\n",
      "\n",
      "[34/34] Processing USDTRY...\n",
      "\n",
      "================================================================================\n",
      "SUPERVISED TRAINING: USDTRY\n",
      "================================================================================\n",
      "\n",
      "Loading data from: /Volumes/Containers/Sequence/data/data/usdtry/usdtry_prepared.csv\n",
      "âœ— USDTRY failed: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdtry/usdtry_prepared.csv'\n",
      "\n",
      "################################################################################\n",
      "ALL TRAINING COMPLETE\n",
      "################################################################################\n",
      "Total session time: 0s\n",
      "Pairs processed: 34/34\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Track results for all pairs\n",
    "all_results = []\n",
    "\n",
    "print(f\"\\n{'#'*80}\")\n",
    "print(f\"MULTI-PAIR TRAINING SESSION\")\n",
    "print(f\"{'#'*80}\")\n",
    "print(f\"Mode: {TRAINING_MODE.upper()}\")\n",
    "print(f\"Pairs: {', '.join([p.upper() for p in PAIRS])}\")\n",
    "print(f\"Total pairs: {len(PAIRS)}\")\n",
    "print(f\"{'#'*80}\\n\")\n",
    "\n",
    "import time\n",
    "session_start_time = time.time()\n",
    "\n",
    "for idx, pair in enumerate(PAIRS, 1):\n",
    "    print(f\"\\n[{idx}/{len(PAIRS)}] Processing {pair.upper()}...\")\n",
    "    \n",
    "    try:\n",
    "        if TRAINING_MODE == 'supervised':\n",
    "            result = train_supervised(pair, SUPERVISED_CONFIG)\n",
    "        elif TRAINING_MODE == 'sac':\n",
    "            result = train_sac(pair, SAC_CONFIG)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown training mode: {TRAINING_MODE}\")\n",
    "        \n",
    "        all_results.append(result)\n",
    "        print(f\"âœ“ {pair.upper()} completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— {pair.upper()} failed: {e}\")\n",
    "        all_results.append({\n",
    "            'pair': pair,\n",
    "            'error': str(e)\n",
    "        })\n",
    "    \n",
    "    # Show remaining pairs\n",
    "    if idx < len(PAIRS):\n",
    "        remaining = PAIRS[idx:]\n",
    "        print(f\"\\nRemaining pairs: {', '.join([p.upper() for p in remaining])}\")\n",
    "\n",
    "session_elapsed_time = time.time() - session_start_time\n",
    "\n",
    "print(f\"\\n{'#'*80}\")\n",
    "print(f\"ALL TRAINING COMPLETE\")\n",
    "print(f\"{'#'*80}\")\n",
    "print(f\"Total session time: {format_time(session_elapsed_time)}\")\n",
    "print(f\"Pairs processed: {len(all_results)}/{len(PAIRS)}\")\n",
    "print(f\"{'#'*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING RESULTS SUMMARY\n",
      "================================================================================\n",
      "  pair                                                                                                    error\n",
      "eurusd [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurusd/eurusd_prepared.csv'\n",
      "eurgbp [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurgbp/eurgbp_prepared.csv'\n",
      "eurjpy [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurjpy/eurjpy_prepared.csv'\n",
      "eurchf [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurchf/eurchf_prepared.csv'\n",
      "euraud [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/euraud/euraud_prepared.csv'\n",
      "eurcad [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurcad/eurcad_prepared.csv'\n",
      "eurnzd [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/eurnzd/eurnzd_prepared.csv'\n",
      "gbpusd [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpusd/gbpusd_prepared.csv'\n",
      "gbpjpy [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpjpy/gbpjpy_prepared.csv'\n",
      "gbpchf [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpchf/gbpchf_prepared.csv'\n",
      "gbpcad [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpcad/gbpcad_prepared.csv'\n",
      "gbpaud [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpaud/gbpaud_prepared.csv'\n",
      "gbpnzd [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/gbpnzd/gbpnzd_prepared.csv'\n",
      "usdjpy [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdjpy/usdjpy_prepared.csv'\n",
      "usdchf [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdchf/usdchf_prepared.csv'\n",
      "usdcad [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdcad/usdcad_prepared.csv'\n",
      "audusd [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/audusd/audusd_prepared.csv'\n",
      "audjpy [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/audjpy/audjpy_prepared.csv'\n",
      "audcad [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/audcad/audcad_prepared.csv'\n",
      "audchf [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/audchf/audchf_prepared.csv'\n",
      "audnzd [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/audnzd/audnzd_prepared.csv'\n",
      "nzdusd [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/nzdusd/nzdusd_prepared.csv'\n",
      "nzdjpy [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/nzdjpy/nzdjpy_prepared.csv'\n",
      "nzdcad [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/nzdcad/nzdcad_prepared.csv'\n",
      "nzdchf [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/nzdchf/nzdchf_prepared.csv'\n",
      "cadchf [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/cadchf/cadchf_prepared.csv'\n",
      "cadjpy [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/cadjpy/cadjpy_prepared.csv'\n",
      "chfjpy [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/chfjpy/chfjpy_prepared.csv'\n",
      "usdbrl [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdbrl/usdbrl_prepared.csv'\n",
      "usdrub [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdrub/usdrub_prepared.csv'\n",
      "usdinr [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdinr/usdinr_prepared.csv'\n",
      "usdcny [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdcny/usdcny_prepared.csv'\n",
      "usdzar [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdzar/usdzar_prepared.csv'\n",
      "usdtry [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/data/data/usdtry/usdtry_prepared.csv'\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/Containers/Sequence/models/training_results_supervised_20260102_030350.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-640530124.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Save results to JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mresults_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mROOT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'models'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf'training_results_{TRAINING_MODE}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/Containers/Sequence/models/training_results_supervised_20260102_030350.json'"
     ]
    }
   ],
   "source": [
    "# Create summary DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"\\nTRAINING RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save results to JSON\n",
    "results_path = ROOT / 'models' / f'training_results_{TRAINING_MODE}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING_MODE == 'supervised':\n",
    "    # Plot test accuracy comparison\n",
    "    successful_results = [r for r in all_results if 'test_acc' in r]\n",
    "    \n",
    "    if successful_results:\n",
    "        pairs = [r['pair'].upper() for r in successful_results]\n",
    "        test_accs = [r['test_acc'] for r in successful_results]\n",
    "        times = [r['time_elapsed'] / 60 for r in successful_results]  # Convert to minutes\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Test accuracy\n",
    "        axes[0].bar(pairs, test_accs, color='steelblue', alpha=0.8)\n",
    "        axes[0].set_ylabel('Test Accuracy (%)')\n",
    "        axes[0].set_title('Test Accuracy by Pair')\n",
    "        axes[0].grid(True, alpha=0.3, axis='y')\n",
    "        axes[0].axhline(y=50, color='red', linestyle='--', alpha=0.5, label='Random baseline')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Training time\n",
    "        axes[1].bar(pairs, times, color='coral', alpha=0.8)\n",
    "        axes[1].set_ylabel('Training Time (minutes)')\n",
    "        axes[1].set_title('Training Time by Pair')\n",
    "        axes[1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "elif TRAINING_MODE == 'sac':\n",
    "    # Plot final reward comparison\n",
    "    successful_results = [r for r in all_results if 'final_eval_reward_mean' in r]\n",
    "    \n",
    "    if successful_results:\n",
    "        pairs = [r['pair'].upper() for r in successful_results]\n",
    "        rewards = [r['final_eval_reward_mean'] for r in successful_results]\n",
    "        stds = [r['final_eval_reward_std'] for r in successful_results]\n",
    "        times = [r['time_elapsed'] / 60 for r in successful_results]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Final rewards\n",
    "        axes[0].bar(pairs, rewards, yerr=stds, color='mediumseagreen', alpha=0.8, capsize=5)\n",
    "        axes[0].set_ylabel('Final Eval Reward')\n",
    "        axes[0].set_title('Final Evaluation Reward by Pair')\n",
    "        axes[0].grid(True, alpha=0.3, axis='y')\n",
    "        axes[0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Training time\n",
    "        axes[1].bar(pairs, times, color='coral', alpha=0.8)\n",
    "        axes[1].set_ylabel('Training Time (minutes)')\n",
    "        axes[1].set_title('Training Time by Pair')\n",
    "        axes[1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
