{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f325f9b",
   "metadata": {},
   "source": [
    "# Colab / Remote Setup\n",
    "If you are running this in Google Colab, run the cell below to mount your drive, install dependencies, and setup the environment.\n",
    "If running locally, you can skip the installation steps or adjust as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d94d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Google Colab.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "mount failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3182207502.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Mount Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# EDIT THIS PATH: Point to where 'Sequence' repo is located in your Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Detect Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab.\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally.\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        # Mount Drive\n",
    "        drive.mount('/content/drive')\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not mount Google Drive: {e}\")\n",
    "        IN_COLAB = False\n",
    "\n",
    "    if IN_COLAB:\n",
    "        # EDIT THIS PATH: Point to where 'Sequence' repo is located in your Drive\n",
    "        REPO_PATH = \"/content/drive/MyDrive/Sequence\"\n",
    "\n",
    "        if not os.path.exists(REPO_PATH):\n",
    "            # Optional: Clone if needed\n",
    "            # !git clone https://github.com/crichalchemist/Sequence.git $REPO_PATH\n",
    "            print(f\"Warning: {REPO_PATH} does not exist. Please adjust the path.\")\n",
    "        else:\n",
    "            os.chdir(REPO_PATH)\n",
    "            print(f\"Changed working directory to {os.getcwd()}\")\n",
    "        \n",
    "        # Install dependencies\n",
    "        # We assume requirements.txt is in the repo root\n",
    "        !pip install -r requirements.txt\n",
    "        !pip install deepspeed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275dfa8",
   "metadata": {},
   "source": [
    "# Phase 0: Single-GPU Per-Pair Training\n",
    "\n",
    "This notebook runs *phase zero* single-GPU training for one or more pairs using the existing `run/training_pipeline.py` components. It:\n",
    "\n",
    "- Prepares data for each pair\n",
    "- Builds the hybrid agent model\n",
    "- Optionally wraps training in DeepSpeed **stage 0** (no sharding) on a single GPU\n",
    "- Trains and evaluates per pair, saving checkpoints\n",
    "\n",
    "> Tip: Use a fresh Python environment with the repo requirements installed. GPU is optional but recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b18fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2207797779.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mROOT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "# Robust logic to find ROOT (works in notebooks/Colab/VS Code)\n",
    "try:\n",
    "    # If running as a script\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    # If running in a notebook, assume we are in 'notebooks/' or root\n",
    "    # We look for a marker file like 'pyproject.toml' or 'pairs.csv'\n",
    "    cwd = Path.cwd()\n",
    "    if (cwd / \"pairs.csv\").exists():\n",
    "        ROOT = cwd\n",
    "    elif (cwd.parent / \"pairs.csv\").exists():\n",
    "        ROOT = cwd.parent\n",
    "    else:\n",
    "        # Fallback: assume standard structure /Sequence/notebooks -> /Sequence\n",
    "        ROOT = cwd.parents[0] if cwd.name == \"notebooks\" else cwd\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "if str(ROOT / \"run\") not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT / \"run\"))\n",
    "\n",
    "print(f\"Project ROOT: {ROOT}\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Falling back to CPU. Training will be slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from data.prepare_dataset import process_pair\n",
    "\n",
    "# Default data prep knobs (edit as needed)\n",
    "data_prep_defaults = dict(\n",
    "    input_root=ROOT / \"output_central\",  # location of Central-time zips/CSVs\n",
    "    years=None,  # e.g., \"2022,2023\" to restrict\n",
    "    t_in=120,\n",
    "    t_out=10,\n",
    "    target_type=\"classification\",\n",
    "    flat_threshold=0.0001,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    feature_groups=\"all\",\n",
    "    exclude_feature_groups=None,\n",
    "    sma_windows=\"10,20,50\",\n",
    "    ema_windows=\"10,20,50\",\n",
    "    rsi_window=14,\n",
    "    bollinger_window=20,\n",
    "    bollinger_num_std=2.0,\n",
    "    atr_window=14,\n",
    "    short_vol_window=10,\n",
    "    long_vol_window=50,\n",
    "    spread_windows=\"20\",\n",
    "    imbalance_smoothing=5,\n",
    "    intrinsic_time=False,\n",
    "    dc_threshold_up=0.001,\n",
    "    dc_threshold_down=None,\n",
    "    lookahead_window=None,\n",
    "    top_k=3,\n",
    "    predict_sell_now=False,\n",
    "    include_sentiment=False,\n",
    ")\n",
    "\n",
    "\n",
    "def build_loaders_for_pair(pair: str, overrides: dict | None = None):\n",
    "    \"\"\"Prepare train/val/test loaders for a given pair.\"\"\"\n",
    "    cfg = deepcopy(data_prep_defaults)\n",
    "    if overrides:\n",
    "        cfg.update(overrides)\n",
    "\n",
    "    prep_args = SimpleNamespace(pairs=pair, **cfg)\n",
    "    pair_name, loaders = process_pair(pair, prep_args)\n",
    "    num_features = next(iter(loaders[\"train\"]))[0].shape[-1]\n",
    "    return pair_name, loaders, num_features\n",
    "\n",
    "\n",
    "# Smoke-test a small sample (set to True to preview a batch)\n",
    "if False:\n",
    "    sample_pair, sample_loaders, sample_feats = build_loaders_for_pair(\"gbpusd\")\n",
    "    xb, yb = next(iter(sample_loaders[\"train\"]))\n",
    "    print(sample_pair, xb.shape, {k: v.shape for k, v in yb.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: DeepSpeed Stage 0 (no sharding) for single-GPU runs.\n",
    "# If deepspeed is unavailable, the notebook will fall back to standard PyTorch.\n",
    "\n",
    "deepspeed_available = False\n",
    "try:\n",
    "    import deepspeed  # type: ignore\n",
    "\n",
    "    deepspeed_available = True\n",
    "except ImportError:\n",
    "    deepspeed = None  # type: ignore\n",
    "\n",
    "\n",
    "def make_deepspeed_engine(model, optimizer, lr_scheduler=None, train_batch_size: int | None = None, grad_clip: float | None = None):\n",
    "    if not deepspeed_available:\n",
    "        return None, optimizer, lr_scheduler\n",
    "\n",
    "    ds_config = {\n",
    "        \"train_batch_size\": train_batch_size,\n",
    "        \"zero_optimization\": {\"stage\": 0},  # Phase zero\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"fp16\": {\"enabled\": False},\n",
    "        \"bf16\": {\"enabled\": False},\n",
    "    }\n",
    "    \n",
    "    # Add gradient clipping to DeepSpeed config if specified\n",
    "    if grad_clip is not None:\n",
    "        ds_config[\"gradient_clipping\"] = grad_clip\n",
    "    \n",
    "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(\n",
    "        model=model,\n",
    "        model_parameters=model.parameters(),\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        config=ds_config,\n",
    "    )\n",
    "    return engine, optimizer, lr_scheduler\n",
    "\n",
    "\n",
    "print(f\"DeepSpeed available: {deepspeed_available}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722affcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task_type and make_model factory before train_pair\n",
    "# Derive task_type from data_prep configuration\n",
    "task_type = data_prep_defaults.get(\"target_type\", \"classification\")\n",
    "\n",
    "def make_model(num_features: int):\n",
    "    \"\"\"Factory function to construct model for training.\"\"\"\n",
    "    from models.agent_hybrid import HybridAgentModel\n",
    "    \n",
    "    # Instantiate model with required features\n",
    "    model = HybridAgentModel(\n",
    "        num_features=num_features,\n",
    "        num_classes=3,  # Prediction classes\n",
    "        lookahead_window=10,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.agent_eval import evaluate_model\n",
    "from risk.risk_manager import RiskManager\n",
    "from train.core.agent_train import train_model, _compute_losses, _select_outputs, _to_device\n",
    "\n",
    "ckpt_root = ROOT / \"checkpoints\" / \"phase0\"\n",
    "ckpt_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def train_pair(pair: str, use_deepspeed: bool = False):\n",
    "    pair_name, loaders, num_features = build_loaders_for_pair(pair)\n",
    "    model = make_model(num_features)\n",
    "    ckpt_path = ckpt_root / f\"{pair_name}_best.pt\"\n",
    "    train_cfg = make_train_config(ckpt_path)\n",
    "    risk_manager = RiskManager(train_cfg.risk) if getattr(train_cfg, \"risk\", None) and train_cfg.risk.enabled else None\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=train_cfg.learning_rate, weight_decay=train_cfg.weight_decay)\n",
    "    ds_engine = None\n",
    "    if use_deepspeed and deepspeed_available:\n",
    "        ds_engine, optimizer, _ = make_deepspeed_engine(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=None,\n",
    "            train_batch_size=train_cfg.batch_size,\n",
    "            grad_clip=train_cfg.grad_clip,  # Pass grad_clip to DeepSpeed config\n",
    "        )\n",
    "\n",
    "    # Fallback: use the existing high-level trainer if DeepSpeed is off\n",
    "    if ds_engine is None:\n",
    "        history = train_model(\n",
    "            model,\n",
    "            loaders[\"train\"],\n",
    "            loaders[\"val\"],\n",
    "            train_cfg,\n",
    "            task_type=task_type,\n",
    "            risk_manager=risk_manager,\n",
    "        )\n",
    "        eval_metrics = evaluate_model(model, loaders[\"test\"], task_type=task_type, risk_manager=risk_manager)\n",
    "        print(f\"Eval ({pair_name}): {eval_metrics}\")\n",
    "        return history, eval_metrics\n",
    "\n",
    "    # Custom loop with DeepSpeed stage 0\n",
    "    device = torch.device(DEVICE)\n",
    "    ds_engine.train()\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_metric\": []}\n",
    "\n",
    "    for epoch in range(1, train_cfg.epochs + 1):\n",
    "        running_loss = 0.0\n",
    "        for step, batch in enumerate(loaders[\"train\"], start=1):\n",
    "            x, y = _to_device(batch, device)\n",
    "            outputs, _ = ds_engine(x)\n",
    "            logits = _select_outputs(outputs, task_type)\n",
    "            outputs = dict(outputs)\n",
    "            outputs[\"primary\"] = logits\n",
    "            loss, _ = _compute_losses(outputs, y, train_cfg, task_type)\n",
    "            ds_engine.backward(loss)\n",
    "            # Note: gradient clipping is handled by DeepSpeed config\n",
    "            ds_engine.step()\n",
    "            ds_engine.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            if step % log_every == 0:\n",
    "                print(f\"epoch {epoch} step {step} loss {running_loss / step:.4f}\")\n",
    "\n",
    "        train_epoch_loss = running_loss / max(1, len(loaders[\"train\"]))\n",
    "        # evaluate_model returns a dict, not a tuple\n",
    "        val_metrics = evaluate_model(ds_engine.module, loaders[\"val\"], task_type=task_type, risk_manager=risk_manager)\n",
    "        val_loss = val_metrics.get(\"loss\", 0.0)\n",
    "        val_metric = val_metrics.get(\"accuracy\", val_metrics.get(\"mse\", 0.0))\n",
    "        history[\"train_loss\"].append(train_epoch_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_metric\"].append(val_metric)\n",
    "        print(f\"epoch {epoch}/{train_cfg.epochs} train_loss {train_epoch_loss:.4f} val_loss {val_loss:.4f} val_metric {val_metric:.4f}\")\n",
    "\n",
    "    # Final eval and checkpointing\n",
    "    eval_metrics = evaluate_model(ds_engine.module, loaders[\"test\"], task_type=task_type, risk_manager=risk_manager)\n",
    "    print(f\"Eval ({pair_name}): {eval_metrics}\")\n",
    "    ds_engine.save_checkpoint(str(ckpt_root), tag=f\"{pair_name}\")\n",
    "    return history, eval_metrics\n",
    "\n",
    "\n",
    "print(\"Trainer ready. Call train_pair('eurusd') to start.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd892e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters - define before train_pair uses them\n",
    "log_every = 50  # Logging frequency\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 0.0\n",
    "grad_clip = 1.0\n",
    "\n",
    "def make_train_config(ckpt_path: Path):\n",
    "    cfg = TrainingConfig(\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        device=DEVICE,\n",
    "        checkpoint_path=str(ckpt_path),\n",
    "    )\n",
    "    cfg.grad_clip = grad_clip\n",
    "    cfg.log_every = log_every\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1876d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.core.training_config import TrainingConfig\n",
    "# Training/eval hyperparameters\n",
    "pairs_to_run = [\"eurusd\", \"gbpusd\"]  # edit list\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 0.0\n",
    "num_workers = 4\n",
    "pin_memory = torch.cuda.is_available()\n",
    "grad_clip = 1.0\n",
    "log_every = 50\n",
    "\n",
    "def make_train_config(ckpt_path: Path):\n",
    "    cfg = TrainingConfig(\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        device=DEVICE,\n",
    "        checkpoint_path=str(ckpt_path),\n",
    "    )\n",
    "    cfg.grad_clip = grad_clip\n",
    "    cfg.log_every = log_every\n",
    "    return cfg\n",
    "\n",
    "print(\"Hyperparameters configured. Edit pairs_to_run and epochs as needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4beb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.agent_eval import evaluate_model\n",
    "from risk.risk_manager import RiskManager\n",
    "from train.core.agent_train import train_model, _compute_losses, _select_outputs, _to_device\n",
    "\n",
    "ckpt_root = ROOT / \"checkpoints\" / \"phase0\"\n",
    "ckpt_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def train_pair(pair: str, use_deepspeed: bool = False):\n",
    "    pair_name, loaders, num_features = build_loaders_for_pair(pair)\n",
    "    model = make_model(num_features)\n",
    "    ckpt_path = ckpt_root / f\"{pair_name}_best.pt\"\n",
    "    train_cfg = make_train_config(ckpt_path)\n",
    "    risk_manager = RiskManager(train_cfg.risk) if getattr(train_cfg, \"risk\", None) and train_cfg.risk.enabled else None\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=train_cfg.learning_rate, weight_decay=train_cfg.weight_decay)\n",
    "    ds_engine = None\n",
    "    if use_deepspeed and deepspeed_available:\n",
    "        ds_engine, optimizer, _ = make_deepspeed_engine(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=None,\n",
    "            train_batch_size=train_cfg.batch_size,\n",
    "        )\n",
    "\n",
    "    # Fallback: use the existing high-level trainer if DeepSpeed is off\n",
    "    if ds_engine is None:\n",
    "        history = train_model(\n",
    "            model,\n",
    "            loaders[\"train\"],\n",
    "            loaders[\"val\"],\n",
    "            train_cfg,\n",
    "            task_type=task_type,\n",
    "            risk_manager=risk_manager,\n",
    "        )\n",
    "        eval_metrics = evaluate_model(model, loaders[\"test\"], task_type=task_type, risk_manager=risk_manager)\n",
    "        print(f\"Eval ({pair_name}): {eval_metrics}\")\n",
    "        return history, eval_metrics\n",
    "\n",
    "    # Custom loop with DeepSpeed stage 0\n",
    "    device = torch.device(DEVICE)\n",
    "    ds_engine.train()\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_metric\": []}\n",
    "\n",
    "    for epoch in range(1, train_cfg.epochs + 1):\n",
    "        running_loss = 0.0\n",
    "        for step, batch in enumerate(loaders[\"train\"], start=1):\n",
    "            x, y = _to_device(batch, device)\n",
    "            outputs, _ = ds_engine(x)\n",
    "            logits = _select_outputs(outputs, task_type)\n",
    "            outputs = dict(outputs)\n",
    "            outputs[\"primary\"] = logits\n",
    "            loss, _ = _compute_losses(outputs, y, train_cfg, task_type)\n",
    "            ds_engine.backward(loss)\n",
    "            if train_cfg.grad_clip:\n",
    "                torch.nn.utils.clip_grad_norm_(ds_engine.parameters(), train_cfg.grad_clip)\n",
    "            ds_engine.step()\n",
    "            ds_engine.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            if step % log_every == 0:\n",
    "                print(f\"epoch {epoch} step {step} loss {running_loss / step:.4f}\")\n",
    "\n",
    "        train_epoch_loss = running_loss / max(1, len(loaders[\"train\"]))\n",
    "        val_loss, val_metric = evaluate_model(ds_engine.module, loaders[\"val\"], task_type=task_type, risk_manager=risk_manager)\n",
    "        history[\"train_loss\"].append(train_epoch_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_metric\"].append(val_metric)\n",
    "        print(f\"epoch {epoch}/{train_cfg.epochs} train_loss {train_epoch_loss:.4f} val_loss {val_loss:.4f} val_metric {val_metric:.4f}\")\n",
    "\n",
    "    # Final eval and checkpointing\n",
    "    eval_metrics = evaluate_model(ds_engine.module, loaders[\"test\"], task_type=task_type, risk_manager=risk_manager)\n",
    "    print(f\"Eval ({pair_name}): {eval_metrics}\")\n",
    "    ds_engine.save_checkpoint(str(ckpt_root), tag=f\"{pair_name}\")\n",
    "    return history, eval_metrics\n",
    "\n",
    "\n",
    "print(\"Trainer ready. Call train_pair('eurusd') to start.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3683a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_with_deepspeed = False  # set True if deepspeed is installed and you want stage-0 wrapping\n",
    "\n",
    "results = {}\n",
    "for pair in pairs_to_run:\n",
    "    print(f\"\\n=== Training {pair} on {DEVICE} (DeepSpeed={run_with_deepspeed}) ===\")\n",
    "    history, metrics = train_pair(pair, use_deepspeed=run_with_deepspeed)\n",
    "    results[pair] = {\n",
    "        \"history\": history,\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
